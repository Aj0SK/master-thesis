\chapter{Implementation and benchmarking}
\label{kap:kap4}

In this chapter, we focus on important aspects of implementation of the ideas from
previous chapter and the results we obtained using them. First, we describe the
important parts and decisions in our implementation. Then, we describe how we
benchmarked our implementation and the results we obtained.

\section{Implementation}

We decided to make our solution a part of the SDSL library~\citep{gog2014theory}. This
is one of the most matured and versatile libraries implementing succinct data structures.
SDSL is a heavily tested library offering various implementations of succinct
structures such as wavelet tree, FM-index, bit vectors, suffix array and many more.
It allows to easily use different building blocks to implement more complex structures,
i.e. using different bit vector implementations in wavelet tree. On top of this, thorough
tests and benchmarks were devised, mainly by \cite{gog2014optimized}.
The RRR implementations consists of \texttt{rrr\_vector} class that uses the on the fly-decoding
and enables us to use any block size from 3 up to 256. SDSL also provides specialization
of this class for block size 15 that uses the table encoding method. We thus decided to use
this as an underlying solution for the sub-blocks and provided specialized implementations
for block sizes 31, 63 and 127 that are mostly used in the practical scenarios. We tried to
keep the number of changes to the general implementation of \texttt{rrr\_vector} as small as possible.
We have been able to only alter the two functions that the SDSL uses namely \texttt{bin\_to\_nr}
that is used for encoding and \texttt{nr\_to\_bin} used for decoding. As we mentioned, the encoding
is less critical for most of the applications as encoding is done only once at the beginning.
This is why we shall focus more on the decoding implementation.

When implementing our technique based on the divide and conquer for smaller block size,
we put the bigget focus on the performance of subroutine to divide our problem to sub-problems as
solving these sub-problems is done using the table approach and is thus very fast. This
parts consists of finding the pair of classes $(c_1, c_2)$ for our block $B$. After this,
we need to find the number of ways how the first and second sub-block may look.
These numbers can be precomputed as for every class $c$, there is at most $b+1$ ways how to
write it in a form $c_1+c_2$ for valid $c_1$ and $c_2$. After obtaining the number of combinations
for the first and second sub-block, it is then trivial to call sub-routines and combine their result
to obtain decoded block. We devised 3 different methods to find the pair $(c_1, c_2)$ for our block $B$.
We may precompute how many block there are with class pair equal to $(0, c), (1, c-1),\ldots ,
(c, 0)$ and name these numbers $C_{0}\ldots C_{c}$. With known offset of our block we may shift
along these numbers keeping the sum of the $C$ up to $i$-th position.

We used 3 different techniques to find the last index in these prefix sums that is smaller 




\section{Benchmarking}

We benchmarked our code using 3 types of benchmarks. The first type of the bechmarks
were the micro-benchmarks, focusing on measuring the performance of block encoding
and decoding in more artificial setting. The second type of benchmarks was based on
the SDSL benchmarks mainly focusing on the performance of the bit vector but also
on the performance of FM-index when the bit vector is used inside of the FM-index.

\paragraph{Bit vector in FM-index}
Most of the FM-index implementations provide at least methods:
\begin{itemize}
	\item $\mathit{count}(P)$ counts the number of occurrences of $P$ in text $T$
	\item $\mathit{locate}(P)$ returns all positions of pattern $P$ in text $T$
	\item $\mathit{extract}(i, j)$ returns the subsequence $T[i..j]$
\end{itemize}
The reason that the $\mathit{extract}$ method is useful and non-trivial is that FM-index
does not store the original sequence $T$ -- at least not in an easily readable form.
As we have already shown, the bit vector is used in the implementation of the FM-index as it is
used inside of the wavelet tree as was described in section TODO.